# pgc-perf-opt
An unsupervised machine learning (UML) SARS-CoV-2 variant discriminator workflow. UML techniques used are principal components analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE), uniform manifold approximation (UMAP), and agglomerative clustering (AGNES). Produces visualizations of SARS-CoV-2 genome samples with good and intuitive clustering particularly for high k-mer counting k values. Prediction is a nice-to-have feature, but because the UML techniques are mainly designed towards visualization or dimensionality reduction, predictive capabilities will have to be augmented via supervised learning.

The workflow is currently set to only use Philippine SARS-CoV-2 data (see `data/GISAID`) and also filters out samples not collected in the Philippines (see `country_exposure` parameter), but it can be set to use other countries in the parameters section.

# Load Packages
If this project is not running in a project-specific environment (e.g. the pgc-perf-opt Docker image), then the following packages will also have to be installed (and then loaded) for the pipeline to work. We will use the CRAN repository as our main source.
```{r message=FALSE}
options(repos = "https://cloud.r-project.org/")
```

We will use the `pacman` package to conveniently organize our project's packages.
``` {r message=FALSE}
if (!require("pacman"))
  install.packages("pacman")
library(pacman)
```

If we are not running on a tailor-made environment, we also install `xml2` in advance to prepare for Tidyverse installation in Linux. Note that in Windows RStudio, this is installed by default. This is also a good time to demonstrate how our development life cycle took care to maintain intercompatibility between Linux and Windows, and this is most evident in the pipeline and in `helper.R::write_to_log`.
```{r message=FALSE}
if (pacman::p_detectOS() == "Linux" && !pacman::p_exists(xml2, local = TRUE)) {
  install.packages("xml2", dependencies = TRUE, INSTALL_opts = c("--no-lock"))
  pacman::p_load(xml2)
}
```

Let us use pacman to load add-on packages as desired. Observe that redundancies in dependencies were carefully removed, e.g. `dplyr` and `ggplot2` are already in the `tidyverse` so we can omit them.
```{r messages=FALSE}
pacman::p_load(plyr, dplyr, GGally, ggthemes, ggvis,
               httr, lubridate, plotly, psych,
               rio, markdown, rmarkdown, shiny,
               stringr, tidyr, tidyverse,
               ape, kmer, readr, validate, gsubfn, seqinr,
               umap, htmlwidgets, factoextra, scales,
               Rtsne, tsne, RColorBrewer, ggfortify, devtools,
               ggdendro, dendextend, cluster, colorspace,
               microbenchmark, data.table,
               highcharter, glue)


if (!require(ggbiplot))
  install_github("vqv/ggbiplot", upgrade = FALSE, quiet = TRUE)
pacman::p_load(ggbiplot)

# validate used for %vin% operator 
# gsubfn used to destructure more than one return value
# devtools supports install_github for installing ggbiplot
# Note: Divisive k-means clustering available via kmer::cluster
```

# LOAD SOURCES #############################################
source("code/R/helper.R")
source("code/R/preprocess.R")
source("code/R/kmer-analysis.R")
source("code/R/dim-reduce.R")
source("code/R/clustering.R")

# SET PARAMETERS ###########################################
# pipeline.R general parameters
# stamp <- [get_time():str|NULL]
# if stamp = "", then generated files won't be timestamped
seed <- 1234
stamp <- get_time()
write_fastacsv <- TRUE
kmer_list <- c(3, 5, 7)
# strat_size: no. of samples per stratum. Current nrow(data) = 24671.
# Also consider using sample_frac for proportionate allocation.
# Note that valid strat_size will only be those with corresponding
# files in `data/interm` and `data/kmers`
strat_size <- 100

# preprocess.R::get_sample() parameters
gisaid_data_path <- "data/GISAID"
gisaid_extract_path <- "data/GISAID/datasets"
country_exposure <- "Philippines"

# preprocess.R::auxiliary parameters
interm_write_path <- "data/interm"
compile_write_path <- "data/overview"
treemaps_write_path <- "data/overview/treemaps"
heatmaps_write_path <- "data/overview/heatmaps"

# dim-reduce.R::dim_reduce() parameters
kmers_data_path <- "data/kmers"
dimreduce_write_path <- "results/dim-reduce/R"
tsne_perplexity <- 40
tsne_max_iter <- 1000
tsne_initial_dims <- 50
umap_n_neighbors <- 15
umap_metric <- "euclidean"
umap_min_dist <- 0.1
color <- "variant"
shape <- "year"
include_plots <- TRUE

# dim-reduce.R::dim_reduce() filtering parameters - OPTIONAL
# factor1 <- "variant"
# values1 <- c("Omicron", "Omicron Sub")
# factor2 <- "year"
# values2 <- c("2023")

# clustering-x.R::dendogram_create_x() parameters
agnes_write_path <- "results/dendrogram"

# RUN PIPELINE #############################################

# Step 1: get_sample()
list[fasta_all, metadata_all] <- get_sample(gisaid_data_path,
                                            gisaid_extract_path,
                                            seed, strat_size,
                                            country_exposure)

# Step 1.5A: sanitize_sample()
metadata_all <- sanitize_sample(metadata_all)

# Step 1.5B: generate_interm()
# Note that at strat_size > nrow(Omicron), you'll be writing around 700MB
# of fasta_all_stamp.csv, so be cautious of generate_interm's space usage.
if (write_fastacsv)
  generate_interm(fasta_all, metadata_all, interm_write_path, stamp)

# Step 1.5C: compile_overview()
# compile_overview drops the submitting_lab and authors column
# after compilation, hence the reassignment to metadata_all.
metadata_all <- compile_overview(metadata_all, compile_write_path, stamp)

# Step 1.5D: make_treemaps()
# NOTE: The treemap() function in helper.R
# can generate any treemap you can think of, yeah!
#make_treemaps(metadata_all, treemaps_write_path, stamp)

# Step 2: get_kmers()
for (k in kmer_list) {
  get_kmers(fasta_all, metadata_all, k, stamp)
}

# GET KMERS FROM PRE-WRITTEN FILES (depends on strat_size)
# kmers is list of kmer dataframes
kmers <- list()
for (i in 1:length(kmer_list)) {
  k <- kmer_list[i]
  k_path <- sprintf("%s/kmer_%d_%d.csv", kmers_data_path, k, strat_size)
  message(sprintf("Reading %s for later... ", k_path), appendLF = FALSE)
  kmers[[i]] <- utils::read.csv(k_path)
  message("DONE!")
}

# Step 2.5: generate_heatmap()
# for (i in 1:length(kmer_list)) {
#   k <- kmer_list[i]
#   generate_heatmap(kmers[[i]], heatmaps_write_path, k)
# }

# Step 3: dim_reduce()
for (i in 1:length(kmer_list)) {
  k <- kmer_list[i]
  dim_reduce(k, kmers[[i]], dimreduce_write_path,
             tsne_seed = seed, tsne_perplexity,
             tsne_max_iter, tsne_initial_dims,
             umap_seed = seed, umap_n_neighbors,
             umap_metric, umap_min_dist, color = color, shape = shape,
#             filter1_factor = factor1, filter1_values = values1, # OPTIONAL
#             filter2_factor = factor2, filter2_values = values2, # OPTIONAL
             include_plots = include_plots)
}

#Step 4: AGNES Clustering by Variant
for (i in 1:length(kmer_list)) {
  k <- kmer_list[i]
  dendrogram_create_variant(k, kmers[[i]], agnes_write_path, include_plots)
}

#Step 5: AGNES Clustering by Region
for (i in 1:length(kmer_list)) {
  k <- kmer_list[i]
  dendrogram_create_region(k, kmers[[i]], agnes_write_path, include_plots)
}

message("All operations completed successfully!")

# CLEAN UP #################################################

# Clear environment
rm(list = ls()) 

# Clear packages (unloading them before another adds another compat check)
p_unload(all)  # Remove all add-ons

# Clear plots but only if there IS a plot
while (!is.null(dev.list())) dev.off()

# Clear console
# cat("\014")  # ctrl+L

# Clear mind :)